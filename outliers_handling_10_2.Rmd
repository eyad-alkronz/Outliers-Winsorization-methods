---
title: A comparative study on Univariate Outliers Winsorization methods in Data Science
  Context
author: "Iyad Alkrunz"
date: "12/26/2021"
output:
  pdf_document:
    latex_engine: xelatex
  html_document:
    df_print: paged
---
 
```{r  echo=FALSE , warning=FALSE , error=FALSE ,include=FALSE}
library(robust)
library(dplyr)
library(ggplot2)
library(MLmetrics )
library(SimDesign)
library(tidyr)
library(stringr)


```



Abstract


**Keywords**
Capping; Flooring; Outlier; Quantile-based. 

# Introduction

Outliers are values in data that differ extremely from a major sample of the data, the presence of outliers can bias the estimates and, as a consequence, significantly reduce the performance and accuracy of a predictable model. 
The problem of outlier-detection has attracted the attention of many statisticians and data scientists. (References).

The methods of outlier-detection are broadly classified into different classes, namely distribution-based methods, depth-based methods, and density-based methods (Preparata and Shamos, 1988, Dominguesa, et al 2018).

The argument on the handling of outliers is continued between the belief of Tukey (1959) that rejecting outliers indiscriminately is inappropriate, and other various trimming and winsorization techniques. Thus, after detection, outliers are handled in one of three ways: accommodation, omission, or winsorization.

The accommodation is utilized by robust statistical methods in order to resist the effect of outliers on the parameter estimates (Ekezie & Ogu, 2013), which indirectly destroy the conclusions of the study (Hubert et al., 2008, Farcomeni & Ventura, 2010).
Trimming of outliers has been well studied, where (Lix and Keselman, 1998; Yusof et al. 2013) have proved its beneficial in terms of robustness, while the type (symmetric or asymmetric) and percentage of trimming have been discussed by (Babu et al. 1999; Wilcox, 2003).

In winsorization, the extreme values are replaced by other appropriate values to reduce the effect of the outliers on the estimation and modeling power (Frey, 2018). The choose of winsorization percentage cut-off point as well as the winsorization statistic are challenging. A poor choice of winsorization percentage will inflated the mean squared errors (MSE) of desired estimators. Thus, it is recommended the choose cut-off point that minimizes the MSE compared to the classical estimator.

In the context of data science, practitioners used different statistics for winsorization, such as mean, median and quantiles *(References)*.
To the best of our knowledge, no study has been published dealing with the impact of different winsorization statistics the estimators.
This paper investigates the impact of four winsorization statistics viz mean, median, mode and Quantile-based Flooring and Capping technique on the estimates of parameters of three distributions, namely normal, negative binomial and exponential distributions.


 


# Outliers and Winsorization

## Sources and Impact of Outliers

Observed variables often contain outliers that differ extremely from a major sample of the data. Some data sets may come from homogeneous groups; others from heterogeneous groups that have different characteristics regarding a specific variable, such as height data not stratified by gender. Outliers can be caused by incorrect measurements, including data entry errors, or by sampling from a different population than the rest of the data (Frost, 2020).

Outliers may cause a negative effect on data analyses such as biasing the estimation, reduce the predictability of constructed model, or it may provide useful information about data when we look into an unusual response to a given study. The data must be evaluated for the presence of outliers before beginning the procedure with the main bulk of data. Thus, outlier detection is an important part of data analysis in the above two cases.

## Outliers Detection 

There are different ways and methods of identifying outliers, including square root transformation, median absolute deviation, Grubb's test, Ueda's method as explained recently by (Shimizu, 2022). In this paper we are going to use Tukey's method boxplot (Tukey, 1977); due to its popularity and less sensitivity of outliers' existance compare to other tests.

Boxplot is a well-known simple graphical tool to display information about continuous univariate data based on five summaries, namely, median, lower quartile $Q_1$, upper quartile $Q_3$, lower extreme, and upper extreme of a data set. It is less sensitive to extreme values of the data than the previous methods using the sample mean and standard variance because it uses quartiles which are resistant to extreme values. The rule of the method is that any value smaller than the lower fence $L_F=Q1 - \nu*IQR$ or larger than the upper fence $U_F=Q3+ \nu*IQR$ is a possible outlier, where $\nu$ is the resistance factor and the interquariles range $IQR=Q_3 -Q_1$. 

Different values of $\nu$ can be considered, but the nominal value is $\nu=1.5$ (Hoaglin, et al, 1986). Various versions of the boxplot were also proposed (See Abuzaid et al; 2012, Saeger et al; 2016).

 
 The following subsection discusses the treatment of outliers via winsorization. 


## Winsorization of outliers
There are  two common methods for treating outliers in a data set. The first is to remove outliers as a means of trimming the data set. The second  method involves replacing the values of outliers with suitable statistic such as mean, median, mode or quantile-based technique as follows: 

$1.\ Replace\ outliers\ by\ mean:$
In this technique the outliers are replaced with the arthematic mean $\bar{x}=\sum_{i=1}^n \frac{x_i}{n}$ of the remaining observations after removing outliers. 

$2.\ Replace\ outliers\ by\ median:$ 
The median value that is the middle value in a ordered remaining observations 
$$Q_2 =\bigg\{ \begin{aligned} 
 &x_{\frac {n+1}{2}}  \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \text{if $n$ is odd}  \nonumber\\   
 &\big(x_{\frac {n}{2}} + x_{\frac {n}{2}+1} \big)/2 \,\,\,\,\,\,\,\,\,\,\, \text{if $n$ is even} \nonumber
\end{aligned}$$

is used to replace the detected outliers. 

$3.\ Replace \ outliers  \ by \ mode:$
The outliers are replaced with the mode value of the remaining observations, which is appears most often in a set of data values.

$4. Quantile-based \ Flooring \ and \ Capping:$ 
in this quantile-based technique, the maximum outliers are replaced with upper fence $U_F$ (capped), and the minimum outliers are replaced with lower fence $L_F$  (floored).


The following section investigates the effect of the four considered winsorization statistics on the performance of parameter estimates for different probability distributions via Monte carlo simulation.



# Simulation (Numerical Study)

An R code has been developed and implemented in $R$ Studio environment to generate random data sets from three different probability distributions namely, normal, negative binomial and exponential distribution. 


## Settings of Data Generation
Data were generated with four different sample sizes, $n$ = 20,50,100 and 200, in such a way that ($1-\epsilon$) of data are generated from the original distribution ($P$) and the rest $\epsilon$ of data are generated from the contamination distribution ($Q$). Thus, the contaminated data structure can be formulated as $P_{\epsilon}=(1-\epsilon)P+\epsilon Q$, where $\epsilon$ is the contamination level and $\epsilon$ =0.05, 0.10 or 0.15.The following three probability distributions are considered:

### Normal distribution
For normal random variable, $X\sim N(\mu,\sigma^2)$; data were generated from the standard normal distribution with $\mu = 0$ and $\sigma^= 1$. For contamination procedur; the contaminated data were generated from another normal distribution with $\mu = 4$ and $\sigma = 2$.  

The maximum likelihood estimator ($MLE$) of the mean and standard deviation  are obtained as the sample mean $\hat{\mu}_{mle} = \bar{x} = \frac{1}{n} \sum_{i=1}^n x_i$,and  $\hat{\sigma} = \sqrt{\frac{\sum (x_{i} - \bar{x})^{2}}{n - 1}}$, respectively.

### Negative binomial distribution
Random variable $X$ follows the negative binomial distribution $X \sim NB(k,p)$ with mean $\mu =\frac{k}{p}$ and variance $\sigma^2= \frac{k(1-p)}{p^2}$ if $X$ is the count of independent Bernoulli trials required to achieve the $k^{th}$ successful trials when the probability of success is a constant $p$. The probability of $x=n$ trials is $f(X=n)= {n-1 \choose k-1} p^k (1-p)^{n-k}$.  The $MLE$ of $p$ is given by: $\hat{p} = \frac{k}{x + k}$.

For negative binomial random variable; data are generated with parameters $k=2$ and $p=0.2$, while the contaminated data are generated from Poisson distribution with $\lambda = 32$, where the probability of $k$ successes is $P(X=k) = \frac {(e^{\lambda} \lambda^k)} {k!}$.
 

### Exponential distribution
The Exponential distribution is the most commonly used model in reliability and life-testing analysis, (i.e $f(x)=\theta e^{-\theta x}$ for $x \geq 0$). The $MLE$ of $\theta$ is given by $\hat{\theta}= \frac{1}{\bar{x}}$.  
Data were generated with parameter $\theta = 0.5$, and the contaminated data were generated from exponential distribution with $\theta = 0.05$.  

 
For each combination of the considered probability distributions,sample sizes, contamination levels and winsorization statistics; the generation procedures are repeated 1000 iterations to ensure the convergence.
 

 
## Performance indicators 
The impact of the considered four outliers winsorization statistics on the parameter estimates are measured by three common indicators as follows:

1. $Bias$, is the difference between the estimator's expected value and the true value of the parameter being estimated.

2. $Mean \ Square\ Error (MSE)$, is a measure of the quality of an estimator. As it is derived from the square of Euclidean distance, it is always a positive value that decreases as the error approaches zero. $Write\ the\ formula$.

3. $Goodness\ of\ fit\ tests$, are statistical tests aiming to determine whether a set of observed values match those expected under the applicable distribution. There are different goodness-of-fit tests, in this article the Shipiro-Wilk test is used in the case of normal and exponential distributions, while Kolmogorov-Smirnov test is used in the case of negative binomial distribution.


 
## Results

```{r  echo=FALSE ,warning=FALSE,error=FALSE}

finalResult_Normal <- read.csv("Normal_Data\\normalResult.csv")
finalResult_NB <- read.csv("NB_Data\\NB_Result.csv")
finalResult_EXP <- read.csv("Exp_Data\\EXP_Result.csv")


#merge three results 
 

norm_data <- finalResult_Normal %>% select( sampleSize , contamination, MSE_XBar_Q_b_F_C , MSE_XBar_Mean , MSE_XBar_Median , MSE_XBar_Mode) %>% gather("Method" , "value" ,
                       MSE_XBar_Q_b_F_C , MSE_XBar_Mean , MSE_XBar_Median , MSE_XBar_Mode )
norm_data$label = "Normal Distribution MSE_XBar"

norm_data2 <- finalResult_Normal %>% select( sampleSize , contamination, MSE_SD_Q_b_F_C , MSE_SD_Mean , MSE_SD_Median , MSE_SD_Mode) %>% gather("Method" , "value" ,
                       MSE_SD_Q_b_F_C , MSE_SD_Mean , MSE_SD_Median , MSE_SD_Mode )
norm_data2$label = "Normal Distribution MSE_SD"


#################### NB #########################
nb_data<- finalResult_NB %>% select( sampleSize , contamination,MSE_prop_Q_b_F_C  , MSE_prop_Mean, MSE_prop_Median , MSE_prop_Mode) %>% 
  gather("Method" , "value" ,  MSE_prop_Q_b_F_C  , MSE_prop_Mean, MSE_prop_Median , MSE_prop_Mode )
nb_data$label = "Negative binomial distribution MSE_prop"
 
######################## EXP ############################
 

exp_data <- finalResult_EXP %>% filter(rate==0.5)  %>% select( sampleSize , contamination,MSE_rate_Q_b_F_C  , MSE_rate_Mean, MSE_rate_Median , MSE_rate_Mode , MSE_rate_Before) %>% 
  gather("Method" , "value" ,  MSE_rate_Q_b_F_C  , MSE_rate_Mean, MSE_rate_Median , MSE_rate_Mode ,MSE_rate_Before )
exp_data$label = "Exponential distribution MSE_rate"



 
 mergData <- norm_data%>%rbind(norm_data2) %>% rbind(exp_data) %>% rbind(nb_data)
 
```

```{r  echo=FALSE ,warning=FALSE,error=FALSE}


mergData %>% filter(contamination == 10) %>% 
  filter(
  (label == "Normal Distribution MSE_XBar" & Method=="MSE_XBar_Median") |
  (label == "Normal Distribution MSE_SD" & Method=="MSE_SD_Mean") |
  (label == "Negative binomial distribution MSE_prop" & Method=="MSE_prop_Mode") |
  (label == "Exponential distribution MSE_rate" & Method=="MSE_rate_Q_b_F_C")   
    ) %>%
  
 ggplot(aes(x = (sampleSize) , y = value)) + 
  geom_point( aes(colour = as.factor(Method)   )) + 
    geom_line( aes( colour =  as.factor(Method) )) +
    labs(title = ""
       ,subtitle =  "" ,  colour = ""  , shape =  "" )+
   xlab("sample Size") + ylab("MSE") +
  scale_colour_discrete(
    labels = c( 
     "MSE_prop_Mode" = expression(hat(p)*"  Mode")   , 
     "MSE_rate_Q_b_F_C"=  expression(hat(theta)*"  Q_b_F_C") ,
     "MSE_SD_Mean" =  expression(hat(sigma)*"  Mean") ,
     "MSE_XBar_Median" = expression(hat(mu)*"  Median")
     )
    )+ theme(legend.position = "bottom",
          legend.direction = "horizontal")
  

 
```

 
Regardless the distribution, contamination level or winsorization statistics, the results of simulation studies reveal that, the performance of parameter estimates are improved as the sample size increased, where the MSE has a decreasing function with the sample size, and the bias has a decreasing function of the sample size for n<100 and constant function for n>100, as partially presented in Figure 1.
 
The performance has relatively an inverse relationship with the contamination level $\epsilon$.

For normal distribution, due to its symmetric nature the mean, median and mode winsorization statistics have almost similar effect on the estimates of the parameters estimates (i.e. $\mu$ and $\sigma^2$), while they outperform the quantile-based winsorization statistic. 
For negative binomial case, the mode winsorization statistic outperforms the other winsorization statistics for higher levels of contamination $\epsilon=0.15$, while the mean winsorization statistic performs better than other winsorization statistics for smaller levels of contamination $\epsilon<0.15$
For the exponential distribution, the mean winsorization statistic has the best performance followed by median, mode and then the quantile-based method. This behavior may be referred to the MLE estimator of the $\theta$, which is mainly the sample mean.

From the prospective of goodness of fits tests, in the case of normal distribution, mean, median and mode winsorization statistics have consistent performance with respect to the contamination level and sample size, where the proportion of samples fitted by normal distribution close to 1 when the contamination level is $\epsilon=0.05$. 
 In the case of an exponential distribution, all considered winsorization statistics perform approximately equally and perfectly, where the proportion of samples fitted by exponential distribution close to 1 regardless the sample size or contamination level.  
The proportions of fitted sample by negative binomial are less than the other two distributions.
The quantile-based winsorization statistic has the worst performance compare to other three considered statistics because it accumulates the winsorizated values at the edges of distribution and malforms the nature of distribution.
Thus, the mean winsorization statistic is recommended for most of the cases especially for smaller levels of contaminations. 



\newpage

### Normal Distribution

```{r echo=FALSE ,warning=FALSE,error=FALSE}



megerTableMean <- finalResult_Normal  
megerTableMean$bias_XBar_Q_b_F_C <-  round(megerTableMean$bias_XBar_Q_b_F_C ,3)
megerTableMean$bias_XBar_Mean <-  round(megerTableMean$bias_XBar_Mean ,3)
megerTableMean$bias_XBar_Median <-  round(megerTableMean$bias_XBar_Median ,3)
megerTableMean$bias_XBar_Mode <-  round(megerTableMean$bias_XBar_Mode ,3)
megerTableMean$MSE_XBar_Q_b_F_C <-  round(megerTableMean$MSE_XBar_Q_b_F_C ,3)
megerTableMean$MSE_XBar_Mean <-  round(megerTableMean$MSE_XBar_Mean ,3)
megerTableMean$MSE_XBar_Median <-  round(megerTableMean$MSE_XBar_Median ,3)
megerTableMean$MSE_XBar_Mode <-  round(megerTableMean$MSE_XBar_Mode ,3)

 

megerTableMean$Quantile_based <- str_c(megerTableMean$bias_XBar_Q_b_F_C , ' (' , megerTableMean$MSE_XBar_Q_b_F_C , ')' )
megerTableMean$Mean <- str_c(megerTableMean$bias_XBar_Mean , ' (' , megerTableMean$MSE_XBar_Mean , ')' )
megerTableMean$Median <- str_c(megerTableMean$bias_XBar_Median , ' (' , megerTableMean$MSE_XBar_Median , ')' )
megerTableMean$Mode <- str_c(megerTableMean$bias_XBar_Mode , ' (' , megerTableMean$MSE_XBar_Mode , ')' )

megerTableMean %>% select(sampleSize , contamination ,Quantile_based , Mean , Median ,Mode ) %>%
knitr::kable(  
  caption = "Bias (MSE) of the Normal distribution mean estimator for different handling-outliers methods" ,
  col.names = c("n" ,  "$\\epsilon$" ,"Quantile-based", "Mean" , "Median" , "Mode") , escape = FALSE ,
  digits = 3 , align = c("l","l" , "l","l","l","l") 
  ,
  )  %>%
  kableExtra:: kable_classic_2(
    full_width = F,
    position = "center" , 
    latex_options = "striped"
    )%>%
    kableExtra::  kable_styling(latex_options = c("HOLD_position")) %>% 
  kableExtra::add_header_above(c(" " = 2, "Handling-outliers Methods" = 4))




```


```{r echo=FALSE ,warning=FALSE,error=FALSE  }
  

p1 <- finalResult_Normal %>% select( sampleSize , contamination, bias_XBar_Q_b_F_C , bias_XBar_Mean , bias_XBar_Median , bias_XBar_Mode) %>% gather("Method" , "Biased_X_Bar" ,
                       bias_XBar_Q_b_F_C , bias_XBar_Mean , bias_XBar_Median , bias_XBar_Mode ) %>% 
  ggplot(aes(x = (sampleSize) , y = Biased_X_Bar)) + 
  geom_point( aes(colour = as.factor(contamination) ,  shape = as.factor(contamination) )) + 
    geom_line( aes( colour = as.factor(contamination) )) +
    labs(title = "(Bias) Normal distribution mean  "
       ,subtitle =  " for different handling-outliers methods" ,  colour = "\u03B5"  , shape =  "\u03B5")+
  xlab("sample Size") + ylab("Bias")+
  theme(legend.position = "bottom",
          legend.direction = "horizontal")+  
 facet_wrap(.~Method ,  labeller = labeller(Method = 
    c("bias_XBar_Q_b_F_C" = "Quantile-based",
      "bias_XBar_Mean" = "Mean",
      "bias_XBar_Median" = "Median" ,
      "bias_XBar_Mode" = "Mode"
      )
  ))

 
 
p2 <-finalResult_Normal %>% select( sampleSize , contamination, MSE_XBar_Q_b_F_C , MSE_XBar_Mean , MSE_XBar_Median , MSE_XBar_Mode) %>% gather("Method" , "MSE_XBar" ,
                       MSE_XBar_Q_b_F_C , MSE_XBar_Mean , MSE_XBar_Median , MSE_XBar_Mode ) %>% 
  
  ggplot(aes(x = (sampleSize) , y = MSE_XBar)) + 
  geom_point( aes(colour = as.factor(contamination) ,   shape = as.factor(contamination))) + 
        geom_line( aes(colour = as.factor(contamination))) + 
labs(title = "(MSE) Normal distribution mean"
       ,subtitle =  " for different handling-outliers methods" , colour = "\u03B5" ,shape ="\u03B5" 
     )+
  xlab("sample Size") + ylab("MSE")+
  theme(legend.position = "bottom",
          legend.direction = "horizontal")+
  facet_wrap(.~Method ,  labeller = labeller(Method = 
    c("MSE_XBar_Q_b_F_C" = "Quantile-based",
      "MSE_XBar_Mean" = "Mean",
      "MSE_XBar_Median" = "Median" ,
      "MSE_XBar_Mode" = "Mode"
      )
  ))

#gridExtra::grid.arrange(p1,p2 ,  ncol = 2 )

```

```{r echo=FALSE ,warning=FALSE,error=FALSE  }

megerTableSD <- finalResult_Normal  
megerTableSD$bias_SD_Q_b_F_C <-  round(megerTableSD$bias_SD_Q_b_F_C ,3)
megerTableSD$bias_SD_Mean <-  round(megerTableSD$bias_SD_Mean ,3)
megerTableSD$bias_SD_Median <-  round(megerTableSD$bias_SD_Median ,3)
megerTableSD$bias_SD_Mode <-  round(megerTableSD$bias_SD_Mode ,3)

megerTableSD$MSE_SD_Q_b_F_C <-  round(megerTableSD$MSE_SD_Q_b_F_C ,3)
megerTableSD$MSE_SD_Mean <-  round(megerTableSD$MSE_SD_Mean ,3)
megerTableSD$MSE_SD_Median <-  round(megerTableSD$MSE_SD_Median ,3)
megerTableSD$MSE_SD_Mode <-  round(megerTableSD$MSE_SD_Mode ,3)



megerTableSD$Quantile_based <- str_c(megerTableSD$bias_SD_Q_b_F_C , ' (' , megerTableSD$MSE_SD_Q_b_F_C , ')' )
megerTableSD$Mean <- str_c(megerTableSD$bias_SD_Mean , ' (' , megerTableSD$MSE_SD_Mean , ')' )
megerTableSD$Median <- str_c(megerTableSD$bias_SD_Median , ' (' , megerTableSD$MSE_SD_Median , ')' )
megerTableSD$Mode <- str_c(megerTableSD$bias_SD_Mode , ' (' , megerTableSD$MSE_SD_Mode , ')' )


 megerTableSD %>% select(sampleSize , contamination ,Quantile_based , Mean , Median ,Mode ) %>%
knitr::kable(  
  caption = "Bias (MSE) of the Normal distribution standared deviation estimator for different handling-outliers methods" ,
  col.names = c("n" ,  "$\\epsilon$" ,"Quantile-based", "Mean" , "Median" , "Mode") , escape = FALSE ,
  digits = 3 , align = c("l","l" , "l","l","l","l") 
  ,
  )  %>%
  kableExtra:: kable_classic_2(
    full_width = F,
    position = "center" , 
    latex_options = "striped"
    )%>%
    kableExtra::  kable_styling(latex_options = c("HOLD_position")) %>% 
  kableExtra::add_header_above(c(" " = 2, "Handling-outliers Methods" = 4))


```
 


```{r echo=FALSE ,warning=FALSE,error=FALSE  }
 
 

p4 <- finalResult_Normal %>% select( sampleSize , contamination, bias_SD_Q_b_F_C , bias_SD_Mean , bias_SD_Median , bias_SD_Mode) %>% gather("Method" , "Biased_X_SD" ,
                       bias_SD_Q_b_F_C , bias_SD_Mean , bias_SD_Median , bias_SD_Mode ) %>% 
  ggplot(aes(x = (sampleSize) , y = Biased_X_SD)) + 
  geom_point( aes(colour = as.factor(contamination)  , shape = as.factor(contamination) )) + 
      geom_line( aes(colour = as.factor(contamination))) + 
labs(title = "(Bias) Normal distribution estimator"
       ,subtitle =  " for different handling-outliers methods"  , colour = "\u03B5" ,shape ="\u03B5" 
     )+
   theme(legend.position = "bottom",
          legend.direction = "horizontal")+  
  xlab("sample Size") + ylab("(Bias) standared error estimator")+
 facet_wrap(.~Method ,  labeller = labeller(Method = 
    c("bias_SD_Q_b_F_C" = "Quantile-based",
      "bias_SD_Mean" = "Mean",
      "bias_SD_Median" = "Median" ,
      "bias_SD_Mode" = "Mode"
      )
  ))

p5 <- finalResult_Normal %>% select( sampleSize , contamination, MSE_SD_Q_b_F_C , MSE_SD_Mean , MSE_SD_Median , MSE_SD_Mode) %>% gather("Method" , "MSE_SD" ,
                       MSE_SD_Q_b_F_C , MSE_SD_Mean , MSE_SD_Median , MSE_SD_Mode ) %>% 
  ggplot(aes(x = (sampleSize) , y = MSE_SD)) + 
  geom_point( aes(colour = as.factor(contamination)  , shape = as.factor(contamination) )) + 
        geom_line( aes(colour = as.factor(contamination))) + 
labs(title = "(MSE) Normal distribution estimator"
       ,subtitle =  " for different handling-outliers methods"  , colour = "\u03B5" ,shape ="\u03B5" 
     )+
  xlab("sample Size") + ylab("(MSE) standared error estimator")+
  theme(legend.position = "bottom",
          legend.direction = "horizontal")+
  facet_wrap(.~Method ,  labeller = labeller(Method = 
    c("MSE_SD_Q_b_F_C" = "Quantile-based",
      "MSE_SD_Mean" = "Mean",
      "MSE_SD_Median" = "Median" ,
      "MSE_SD_Mode" = "Mode"
      )
  ))

#gridExtra::grid.arrange(p4,p5 ,  ncol = 2 )

```



 

```{r echo=FALSE ,warning=FALSE,error=FALSE  }
table5 <- finalResult_Normal %>% select(sampleSize , contamination ,above05_Q_b_F_C  , above05_Mean , above05_Median , above05_Mode)
 knitr::kable(table5 ,
caption = "The proportion of samples are fitted by normal distribution at 0.05 level of significance after handling outliers." ,
col.names = c("n" ,  "$\\epsilon$" ,"Quantile-based", "Mean" , "Median" , "Mode") , escape = FALSE ,
  digits = 3 , align = c("l","l" , "c","c","c","c") 
  ,
  )  %>%
  kableExtra:: kable_classic_2(
    full_width = F,
    position = "center" , 
    latex_options = "striped"
    )%>%
    kableExtra::  kable_styling(latex_options = c("HOLD_position")) %>% 
  kableExtra::add_header_above(c(" " = 2, "Handling-outliers Methods" = 4))
 

 
pp<-finalResult_Normal %>% select( sampleSize , contamination, above05_Q_b_F_C , above05_Mean , above05_Median , above05_Mode) %>% gather("Method" , "PValue_above05" ,
                       above05_Q_b_F_C , above05_Mean , above05_Median , above05_Mode ) %>% 
  ggplot(aes(x = (sampleSize) , y = PValue_above05)) + 
   geom_point( aes(colour = as.factor(contamination)  , shape = as.factor(contamination) )) + 
        geom_line( aes(colour = as.factor(contamination))) + 
labs(title = "The proportion of samples are fitted by normal distribution "
       ,subtitle =  "at 0.05 level of significance after handling outliers"  , colour = "\u03B5" ,shape ="\u03B5" 
     )+
    xlab("sample Size") + ylab("proportion of fitted samples")+
   theme(legend.position = "bottom",
          legend.direction = "horizontal")+
  facet_wrap(.~Method ,  labeller = labeller(Method = 
    c("above05_Q_b_F_C" = "Quantile-based",
      "above05_Mean" = "Mean",
      "above05_Median" = "Median" ,
      "above05_Mode" = "Mode"
      )
  ))

 
```





### Negative Binomial Distribution
in Negative Binomial distribution we focused on probability of success, we calculated bias and mean squared error for estimator after applying the four different methods of handling outliers, with different sample sizes and different contamination levels, also we applied  Goodness of fit test namely Kolmogorov-Smirnov Test to determines if sample follows a Negative Binomial distribution

 


```{r  echo=FALSE ,warning=FALSE,error=FALSE}

megerTableProp <- finalResult_NB  
megerTableProp$bias_prop_Q_b_F_C <-  round(megerTableProp$bias_prop_Q_b_F_C ,3)
megerTableProp$bias_prop_Mean <-  round(megerTableProp$bias_prop_Mean ,3)
megerTableProp$bias_prop_Median <-  round(megerTableProp$bias_prop_Median ,3)
megerTableProp$bias_prop_Mode <-  round(megerTableProp$bias_prop_Mode ,3)

megerTableProp$MSE_prop_Q_b_F_C <-  round(megerTableProp$MSE_prop_Q_b_F_C ,3)
megerTableProp$MSE_prop_Mean <-  round(megerTableProp$MSE_prop_Mean ,3)
megerTableProp$MSE_prop_Median <-  round(megerTableProp$MSE_prop_Median ,3)
megerTableProp$MSE_prop_Mode <-  round(megerTableProp$MSE_prop_Mode ,3)

 
megerTableProp$Quantile_based <- str_c(megerTableProp$bias_prop_Q_b_F_C , ' (' , megerTableProp$MSE_prop_Q_b_F_C , ')' )
megerTableProp$Mean <- str_c(megerTableProp$bias_prop_Mean , ' (' , megerTableProp$MSE_prop_Mean , ')' )
megerTableProp$Median <- str_c(megerTableProp$bias_prop_Median , ' (' , megerTableProp$MSE_prop_Median , ')' )
megerTableProp$Mode <- str_c(megerTableProp$bias_prop_Mode , ' (' , megerTableProp$MSE_prop_Mode , ')' )


megerTableProp %>% select(sampleSize , contamination ,Quantile_based , Mean , Median ,Mode ) %>%
knitr::kable(  
  caption = "Bias (MSE) of the Negative Binomial Distribution probability of success estimator for different handling-outliers methods" ,
  col.names = c("n" ,  "$\\epsilon$" ,"Quantile-based", "Mean" , "Median" , "Mode") , escape = FALSE ,
  digits = 3 , align = c("l","l" , "l","l","l","l") 
  ,
  )  %>%
  kableExtra:: kable_classic_2(
    full_width = F,
    position = "center" , 
    latex_options = "striped"
    )%>%
    kableExtra::  kable_styling(latex_options = c("HOLD_position")) %>% 
  kableExtra::add_header_above(c(" " = 2, "Handling-outliers Methods" = 4))


 

p1 <- finalResult_NB %>% select( sampleSize , contamination, bias_prop_Q_b_F_C , bias_prop_Mean , bias_prop_Median ,bias_prop_Mode) %>% 
  gather("Method" , "Biased_prop" , bias_prop_Q_b_F_C , bias_prop_Mean , bias_prop_Median ,bias_prop_Mode ) %>% 
  ggplot(aes(x = (sampleSize) , y = Biased_prop)) + 
  geom_point( aes(colour = as.factor(contamination)  , shape = as.factor(contamination) )) + 
        geom_line( aes(colour = as.factor(contamination))) + 
labs(title = "(Bias) Negative Binomial Distribution"
       ,subtitle =  "probability of success estimator "  , colour = "\u03B5" ,shape ="\u03B5" 
     )+
  xlab("sample Size") + ylab("(Bias) probability of success")+
  theme(legend.position = "bottom",
          legend.direction = "horizontal")+
  facet_wrap(.~Method ,  labeller = labeller(Method = 
    c("bias_prop_Q_b_F_C" = "Quantile-based",
      "bias_prop_Mean" = "Mean",
      "bias_prop_Median" = "Median" ,
      "bias_prop_Mode" = "Mode"
      )
  ))

 
 
p2 <-finalResult_NB %>% select( sampleSize , contamination,MSE_prop_Q_b_F_C  , MSE_prop_Mean, MSE_prop_Median , MSE_prop_Mode) %>% 
  gather("Method" , "MSE_prop" ,  MSE_prop_Q_b_F_C  , MSE_prop_Mean, MSE_prop_Median , MSE_prop_Mode ) %>% 
  ggplot(aes(x = (sampleSize) , y = MSE_prop)) + 
  geom_point( aes(colour = as.factor(contamination)  , shape = as.factor(contamination) )) + 
        geom_line( aes(colour = as.factor(contamination))) + 
labs(title = "(MSE) Negative Binomial Distribution"
       ,subtitle =  "probability of success estimator "  , colour = "\u03B5" ,shape ="\u03B5" 
     )+
  xlab("sample Size") + ylab("(MSE) probability of success")+
  theme(legend.position = "bottom",
          legend.direction = "horizontal")+
  facet_wrap(.~Method ,  labeller = labeller(Method = 
    c("MSE_prop_Q_b_F_C" = "Quantile-based",
      "MSE_prop_Mean" = "Mean",
      "MSE_prop_Median" = "Median" ,
      "MSE_prop_Mode" = "Mode"
      )
  ))


#gridExtra::grid.arrange(p1,p2 ,  ncol = 2 )

```


```{r  echo=FALSE ,warning=FALSE,error=FALSE}

table3 <- finalResult_NB %>% select(sampleSize , contamination ,above05_Q_b_F_C  , above05_Mean , above05_Median , above05_Mode)

 knitr::kable(table3 , 
caption = "The proportion of samples are fitted by Negative binomial distribution at 0.05 level of significance after handling outliers." ,
             col.names = c("n" ,  "$\\epsilon$" ,"Quantile-based", "Mean" , "Median" , "Mode") , escape = FALSE ,
  digits = 3 , align = c("l","l" , "c","c","c","c") 
  ,
  )  %>%
  kableExtra:: kable_classic_2(
    full_width = F,
    position = "center" , 
    latex_options = "striped"
    )%>%
    kableExtra::  kable_styling(latex_options = c("HOLD_position")) %>% 
  kableExtra::add_header_above(c(" " = 2, "Handling-outliers Methods" = 4))
 
 

  
ppp <- finalResult_NB %>% select( sampleSize , contamination, above05_Q_b_F_C , above05_Mean , above05_Median , above05_Mode) %>% gather("Method" , "PValue_above05" ,
                       above05_Q_b_F_C , above05_Mean , above05_Median , above05_Mode ) %>% 
  ggplot(aes(x = (sampleSize) , y = PValue_above05)) + 
 geom_point( aes(colour = as.factor(contamination)  , shape = as.factor(contamination) )) + 
        geom_line( aes(colour = as.factor(contamination))) + 
labs(title = "The proportion of samples are fitted by Negative binomial distribution "
       ,subtitle =  "at 0.05 level of significance after handling outliers"  , colour = "\u03B5" ,shape ="\u03B5" 
     )+
    xlab("sample Size") + ylab("proportion of fitted samples")+
   theme(legend.position = "bottom",
          legend.direction = "horizontal")+
  facet_wrap(.~Method ,  labeller = labeller(Method = 
    c("above05_Q_b_F_C" = "Quantile-based",
      "above05_Mean" = "Mean",
      "above05_Median" = "Median" ,
      "above05_Mode" = "Mode"
      )
  ))
```



### Exponential distribution
Exponential distribution has only one parameter $\lambda$, we calculated bias and mean squared error for  estimator after applying the four different methods of handling outliers, with different sample sizes and different contamination levels, also we applied  Goodness of fit test namely Chi-Square Test to determines if sample follows a Exponential distribution
 


```{r  echo=FALSE ,warning=FALSE,error=FALSE}

megerTableRate <- finalResult_EXP  
megerTableRate$bias_rate_Before <-  round(megerTableRate$bias_rate_Before ,3)
megerTableRate$bias_rate_Q_b_F_C <-  round(megerTableRate$bias_rate_Q_b_F_C ,3)
megerTableRate$bias_rate_Mean <-  round(megerTableRate$bias_rate_Mean ,3)
megerTableRate$bias_rate_Median <-  round(megerTableRate$bias_rate_Median ,3)
megerTableRate$bias_rate_Mode <-  round(megerTableRate$bias_rate_Mode ,3)

megerTableRate$MSE_rate_Before <-  round(megerTableRate$MSE_rate_Before ,3)
megerTableRate$MSE_rate_Q_b_F_C <-  round(megerTableRate$MSE_rate_Q_b_F_C ,3)
megerTableRate$MSE_rate_Mean <-  round(megerTableRate$MSE_rate_Mean ,3)
megerTableRate$MSE_rate_Median <-  round(megerTableRate$MSE_rate_Median ,3)
megerTableRate$MSE_rate_Mode <-  round(megerTableRate$MSE_rate_Mode ,3)

 
megerTableRate$Before <- str_c(megerTableRate$bias_rate_Before , ' (' , megerTableRate$MSE_rate_Before , ')' )
megerTableRate$Quantile_based <- str_c(megerTableRate$bias_rate_Q_b_F_C , ' (' , megerTableRate$MSE_rate_Q_b_F_C , ')' )
megerTableRate$Mean <- str_c(megerTableRate$bias_rate_Mean , ' (' , megerTableRate$MSE_rate_Mean , ')' )
megerTableRate$Median <- str_c(megerTableRate$bias_rate_Median , ' (' , megerTableRate$MSE_rate_Median , ')' )
megerTableRate$Mode <- str_c(megerTableRate$bias_rate_Mode  , ' (' , megerTableRate$MSE_rate_Mode , ')' )


megerTableRate %>% select(sampleSize , contamination ,Before ,Quantile_based , Mean , Median ,Mode ) %>%
knitr::kable(  
  caption = "Bias (MSE) of the exponential distribution Rate estimator for different handling-outliers methods" ,
  col.names = c("n" ,  "$\\epsilon$" ,"Before","Quantile-based", "Mean" , "Median" , "Mode") , escape = FALSE ,
  digits = 3 , align = c("l","l" , "l","l","l","l") 
  ,
  )  %>%
  kableExtra:: kable_classic_2(
    full_width = F,
    position = "center" , 
    latex_options = "striped"
    )%>%
    kableExtra::  kable_styling(latex_options = c("HOLD_position")) %>% 
  kableExtra::add_header_above(c(" " = 3, "Handling-outliers Methods" = 4))


 
 


p1 <-finalResult_EXP %>% filter(rate==0.5) %>% select( sampleSize , contamination, bias_rate_Q_b_F_C , bias_rate_Mean , bias_rate_Median ,bias_rate_Mode , bias_rate_Before) %>% 
  gather("Method" , "Biased_rate" , bias_rate_Q_b_F_C , bias_rate_Mean , bias_rate_Median ,bias_rate_Mode , bias_rate_Before ) %>% 
  ggplot(aes(x = (sampleSize) , y = Biased_rate)) + 
  geom_point( aes(colour = as.factor(contamination)  , shape = as.factor(contamination) )) + 
        geom_line( aes(colour = as.factor(contamination))) + 
labs(title = "(Bias) Exponential distribution "
       ,subtitle =  "Rate estimator for different handling methods"  , colour = "\u03B5" ,shape ="\u03B5" 
     )+
    xlab("sample Size") + ylab("(Bias) Rate estimator")+
   theme(legend.position = "bottom",
          legend.direction = "horizontal")+
  facet_wrap(.~Method ,  labeller = labeller(Method = 
    c(
      "bias_rate_Before" ="Before" ,
      "bias_rate_Q_b_F_C" = "Quantile-based",
      "bias_rate_Mean" = "Mean",
      "bias_rate_Median" = "Median" ,
      "bias_rate_Mode" = "Mode" 
      )
  ))







p2 <-finalResult_EXP %>% filter(rate==0.5)  %>% select( sampleSize , contamination,MSE_rate_Q_b_F_C  , MSE_rate_Mean, MSE_rate_Median , MSE_rate_Mode , MSE_rate_Before) %>% 
  gather("Method" , "MSE_rate" ,  MSE_rate_Q_b_F_C  , MSE_rate_Mean, MSE_rate_Median , MSE_rate_Mode ,MSE_rate_Before ) %>% 
  ggplot(aes(x = (sampleSize) , y = MSE_rate)) + 
  geom_point( aes(colour = as.factor(contamination)  , shape = as.factor(contamination) )) + 
        geom_line( aes(colour = as.factor(contamination))) + 
labs(title = "(MSE) Exponential distribution "
       ,subtitle =  "Rate estimator for different handling methods"  , colour = "\u03B5" ,shape ="\u03B5" 
     )+
    xlab("sample Size") + ylab("(MSE) Rate estimator")+
   theme(legend.position = "bottom",
          legend.direction = "horizontal")+
  facet_wrap(.~Method ,  labeller = labeller(Method = 
    c(
      "MSE_rate_Before" ="Before" ,
      "MSE_rate_Q_b_F_C" = "Quantile-based",
      "MSE_rate_Mean" = "Mean",
      "MSE_rate_Median" = "Median" ,
      "MSE_rate_Mode" = "Mode" 
      )
  ))



#gridExtra::grid.arrange(p1,p2 ,  ncol = 2 )


```

```{r  echo=FALSE ,warning=FALSE,error=FALSE}

table3 <- finalResult_EXP %>% select(sampleSize , contamination ,above05_Before_P_value ,above05_Q_b_F_C  , above05_Mean , above05_Median , above05_Mode)

 knitr::kable(table3 , 
caption = "The proportion of samples are fitted by Exponential distribution at 0.05 level of significance after handling outliers." ,
             col.names = c("n" ,  "$\\epsilon$" ,"Before","Quantile-based", "Mean" , "Median" , "Mode") , escape = FALSE ,
  digits = 3 , align = c("l","l" , "l","l","l","l") 
  ,
  )  %>%
  kableExtra:: kable_classic_2(
    full_width = F,
    position = "center" , 
    latex_options = "striped"
    )%>%
    kableExtra::  kable_styling(latex_options = c("HOLD_position")) %>% 
  kableExtra::add_header_above(c(" " = 3, "Handling-outliers Methods" = 4))


pppp <- finalResult_EXP %>% select( 
  sampleSize , contamination, above05_Before_P_value ,above05_Q_b_F_C , above05_Mean , above05_Median , above05_Mode) %>% gather("Method" , "PValue_above05" ,
                    above05_Before_P_value ,   above05_Q_b_F_C , above05_Mean , above05_Median , above05_Mode ) %>%
  ggplot(aes(x = (sampleSize) , y = PValue_above05)) +
 geom_point( aes(colour = as.factor(contamination)  , shape = as.factor(contamination) )) + 
        geom_line( aes(colour = as.factor(contamination))) + 
labs(title = "The proportion of samples are fitted by Exponential distribution "
       ,subtitle =  "at 0.05 level of significance after handling outliers"  , colour = "\u03B5" ,shape ="\u03B5" 
     )+
    xlab("sample Size") + ylab("proportion of fitted samples")+
   theme(legend.position = "bottom",
          legend.direction = "horizontal")+
  facet_wrap(.~Method ,  labeller = labeller(Method = 
    c(
      "above05_Before_P_value" ="Before" ,
      "above05_Q_b_F_C" = "Quantile-based",
      "above05_Mean" = "Mean",
      "above05_Median" = "Median" ,
      "above05_Mode" = "Mode" 
      )
  ))



```

 
 
 
 

# REFERENCES

Abuzaid, A. H., Mohamed, I. B. and Hussin, A. G. (2012). Boxplot for Circular Variables. Computational Statistics. 27 (3), 381-392. 

Saeger, T. Kleven, B. Otero, I., Wallace, M. and Ziglar, R.(2016). Outlier Labeling Method for Univariate Data for Module Test and Die Sort. IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING, 29 (4), 330-335.

Nyitrai,T. and Miklos, M. (2019) The effects of handling outliers on the performance of bankruptcy prediction models. Socio-Economic Planning Sciences, 67, 34-42.

Babu GJ, Padmanabhan AR, and Puri ML (1999). Robust One-way ANOVA under Possibly Non Regular Conditions. Biometrical Journal, 41: 321-339.

Dominguesa R, Filipponea M, Michiardia P, Zouaouib J. A Comparative Evaluation of Outlier Detection Algorithms: Experiments and Analyses, Pattern Recogn. 2018; 74: 406-421. 

Ekezie DD and Ogu AI (2013). Statistical Analysis/Methods of Detecting Outliers in Univariate Data in A Regression Analysis Model. International Journal of Education and Research, 1(5): 1-24.

Hubert M, Rousseeuw PJ, and Van Aelst S (2008). High-breakdown Robust Multivariate Methods. Statistical Science, 23(1): 92-119.

Lix LM and Keselman HJ (1998). To Trim or Not to Trim: Tests of Location Equality under Heteroscedasticity and Non-normality. Educational and Psychological Measurement, 115: 335-363.

Preparata F, Shamos M.Computational Geometry: an Introduction, Springer-Verlag, Berlin;1988.

Wilcox RR (2003). Applying Contemporary Statistical Techniques. Academic Press: San Diego, CA. 

Yusof ZM, Othman AR, and Syed Yahaya SS (2013). Robustness of Trimmed F Statistics when Handling Nonnormal Data. Malaysian Journal of Science, 32(1): 73-77.

Frey, B. (2018). The SAGE encyclopedia of educational research, measurement, and evaluation (Vols. 1-4). Thousand Oaks,, CA: SAGE Publications, Inc. doi: 10.4135/9781506326139

Tukey, J. W. (1959). A survey of sampling from contaminated distributions. Princeton, New Jersey: Princeton University.


Seo, S.(2006) A review and comparison of methods for detecting outliers in univariate data sets. Diss. University of Pittsburgh.

Kwak, Sang Kyu, and Jong Hae Kim. "Statistical data preparation: management of missing values and outliers." Korean journal of anesthesiology 70.4 (2017): 407.


Frost J (2020). Hypothesis testing: An intuitive guide for making data drives decisions. Statistics by Jim Publishing State College, Pennysalvia, U.S.A.

Shimizu Y (2022) Multiple Desirable Methods in Outlier Detection of Univariate Data With R Source Codes. Front. Psychol. 12:819854.

Tukey JW (1977) Exploratory data analysis. Addison-Wesley, Reading.

Hoaglin DC, Iglewicz B, Tukey JW (1986) Performance of some resistant rules for outlier labeling. J Am Stat Assoc 81(396):991-999

https://www.redalyc.org/pdf/2990/299023509004.pdf



